import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
from sklearn.pipeline import Pipeline

# Завантаження даних
data = pd.read_csv("internet_service_churn.csv")

# 1. Перевірка на дублікати
print("Кількість дублікатів:", data.duplicated().sum())
data = data.drop_duplicates()  # Видалення дублікатів

# 2. Перевірка на пропущені значення
print("Пропущені значення:")
print(data.isnull().sum())

# Заповнення пропущених значень
numerical_cols = data.select_dtypes(include=[np.number]).columns
for col in numerical_cols:
    if data[col].isnull().sum() > 0:
        data[col].fillna(data[col].median(), inplace=True)  # Заповнюємо медіаною

categorical_cols = data.select_dtypes(include=["object"]).columns
for col in categorical_cols:
    if data[col].isnull().sum() > 0:
        data[col].fillna(data[col].mode()[0], inplace=True)  # Заповнюємо модою

# 3. Аналіз кореляції
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Кореляційна матриця")
plt.show()

# 4. Виявлення викидів
numerical_cols = data.select_dtypes(include=[np.number]).columns
for col in numerical_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=data[col])
    plt.title(f"Boxplot для {col}")
    plt.show()

# Виправлення викидів (обмеження значень)
for col in numerical_cols:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    data[col] = np.where(data[col] < lower_bound, lower_bound, data[col])
    data[col] = np.where(data[col] > upper_bound, upper_bound, data[col])

# 5. Підготовка даних для моделі
data = data.drop(columns=["id"])
data = pd.get_dummies(data, drop_first=True)

# Розділення на X та y
X = data.drop(columns=["churn"])
y = data["churn"]

# Розділення на тренувальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Побудова конвеєра
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("model", XGBClassifier(random_state=42, n_jobs=-1))
])

# Гіперпараметри для крос-валідації
param_grid = {
    "model__n_estimators": [100, 200],
    "model__max_depth": [3, 5, 7],
    "model__learning_rate": [0.01, 0.1],
    "model__subsample": [0.8, 1.0],
    "model__colsample_bytree": [0.8, 1.0]
}

# GridSearchCV
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring="f1", n_jobs=-1)
grid_search.fit(X_train, y_train)

# Найкращі параметри
print("Найкращі параметри:", grid_search.best_params_)

# Оцінка на тестовому наборі
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("F1-score:", f1_score(y_test, y_pred))
